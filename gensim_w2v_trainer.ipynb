{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gensim_w2v_trainer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1278edZcafP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "71caebd8-9d47-4f6f-d13c-127bee1020a9"
      },
      "source": [
        "##### Step 1 : Import library\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from numpy import log, min\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "from collections import defaultdict,Counter\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import pytz\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.models.word2vec import Word2Vec, LineSentence\n",
        "from gensim.models.fasttext import FastText\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import KeyedVectors, LsiModel\n",
        "from gensim.similarities import Similarity,SparseMatrixSimilarity,MatrixSimilarity\n",
        "from multiprocessing import cpu_count\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action = 'ignore', category = UserWarning, module = 'gensim')#忽略警告\n",
        "from google.colab import files, drive\n",
        "!mkdir -p drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0vZpnTMJghd"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 此內容會顯示為程式碼\n",
        "```\n",
        "\n",
        "# define file path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71WXha3JaLlG"
      },
      "source": [
        "##### Step 2 : define time variable\n",
        "\n",
        "\n",
        "os.environ['TZ'] = 'Asia/Hong_Kong'\n",
        "\n",
        "HK_now_datetime=datetime.now().astimezone(tz=pytz.timezone('Asia/Hong_Kong')).replace(tzinfo=None)#-timedelta(hours=4)\n",
        "HK_now_str=HK_now_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
        "HK_today_str=HK_now_str[:10]\n",
        "HK_year_str=HK_now_str[:4]\n",
        "\n",
        "HK_today_file=re.sub('\\-|\\:|\\s','',HK_today_str)\n",
        "HK_now_file=re.sub('\\-|\\:|\\s','',HK_now_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vENn8A7dh5K"
      },
      "source": [
        "##### step 3:  define project path\n",
        "\n",
        "encoding='utf-8'\n",
        "\n",
        "master_dir='/content/gdrive/My Drive/word2vec_training'#\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "co6jmwRtdtrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SDjmcJgwUXM"
      },
      "source": [
        "##### step 4:  define load and clean training data functions\n",
        "\n",
        "def load_tokens(token_file):\n",
        " \n",
        "  with open(token_file,'r',encoding='utf-8') as g:\n",
        "    token_doc=g.readlines()\n",
        "  \n",
        "  return token_doc\n",
        "\n",
        "\n",
        "def cleaning_tokens(token_doc):\n",
        "  t1=[]\n",
        "  for t_str in token_doc:\n",
        "    t_list=re.split(' ',t_str)    \n",
        "    t_list_clean=[re.sub('\\n','',t) for t in t_list if t !='' and len(t)>1]  ## remove blank space and \\n\n",
        "    t1.append(t_list_clean)\n",
        "  \n",
        "\n",
        "  t2=[]\n",
        "  for t_list in t1:\n",
        "    t_clean=[]\n",
        "    for t in t_list:\n",
        "      if t !='' and len(t)>1:\n",
        "        t_clean.append(t)\n",
        "    t2.append(t_clean)\n",
        "\n",
        "  return t2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duDzGTuRdqdf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22lv6kpG_LA8"
      },
      "source": [
        "#### step 4 : import training data\n",
        "\n",
        "## 4.1. load trainingdata : THUCNews \n",
        "THUCNews_data_dir=os.path.join(master_dir,r'tokens', 'THUCNews',)\n",
        "\n",
        "\n",
        "THUC_financial_token_file=os.path.join(THUCNews_data_dir,'finance','THUCNews_finance_Clean.txt')\n",
        "THUC_financial_doc=load_tokens(THUC_financial_token_file)\n",
        "THUC_financial_token=cleaning_tokens(THUC_financial_doc)\n",
        "\n",
        "\n",
        "THUC_fashion_token_file=os.path.join(THUCNews_data_dir,'fashion','THUCNews_fashion_Clean.txt')\n",
        "THUC_fashion_doc=load_tokens(THUC_fashion_token_file)\n",
        "THUC_fashion_token=cleaning_tokens(THUC_fashion_doc)\n",
        "\n",
        "THUC_game_token_file=os.path.join(THUCNews_data_dir,'game','THUCNews_game_Clean.txt')\n",
        "THUC_game_doc=load_tokens(THUC_game_token_file)\n",
        "THUC_game_token=cleaning_tokens(THUC_game_doc)\n",
        "\n",
        "print(THUC_financial_token[:1])\n",
        "print(THUC_fashion_token[:1])\n",
        "print(THUC_game_token[:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdbU27XZN6gg"
      },
      "source": [
        "## 4.2. load trainingdata : lifestyle/DIVA\n",
        "\n",
        "\n",
        "lifestyle_token_dir='/content/gdrive/My Drive/ETNET/news_folders/DIVA/Finance/article_tokens'\n",
        "lifestyle_token_filename='tokens_w2v_20191121.txt' \n",
        "lifestyle_token_file=os.path.join(lifestyle_token_dir,lifestyle_token_filename)\n",
        "\n",
        "with open(lifestyle_token_file,'r',encoding='utf-8') as g:\n",
        "  lifestyle_token_doc=g.readlines()\n",
        "\n",
        "lifestyle_token=cleaning_tokens(lifestyle_token_doc)\n",
        "print(len(lifestyle_token))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bah1Vs6_yrWl"
      },
      "source": [
        "## 4.3. load trainingdata : news \n",
        "newstoken_holder='/content/gdrive/My Drive/ETNET/NER/news/code/PeijiYang/predict_data/corpus'#\n",
        "newstoken_filename='full.txt'\n",
        "\n",
        "newstoken_file=os.path.join(newstoken_holder,newstoken_filename)\n",
        "\n",
        "with open(newtoken_file,'r',encoding='utf-8') as g:\n",
        "  newtoken_doc=g.readlines()\n",
        "\n",
        "newtoken=cleaning_tokens(newtoken_doc)\n",
        "print(newtoken[:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 4.4 combine datasets\n",
        "\n",
        "total_token=THUC_financial_token +THUC_fashion_token+ THUC_game_token+  lifestyle_token + newtoken\n",
        "\n",
        "print(len(total_token))\n",
        "print(total_token[:5])"
      ],
      "metadata": {
        "id": "IlTMvUa5g6UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QL2ZlCf4VjM"
      },
      "source": [
        "## 4.5. load training data :stopwords\n",
        "stopwords_filename='stopwords.txt'\n",
        "stopwords_file=os.path.join(newstoken_holder,stopwords_filename)\n",
        "\n",
        "with open(stopwords_file,'r',encoding='utf-8') as g:\n",
        "  stopwords=[w.strip('\\n').strip(' ').strip() for w in g.readlines()]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhCdebz9h0tD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### step 5 :training and saving \n",
        "\n",
        "### 5.1. define hyper-parameters\n",
        "min_count=1\n",
        "size=300\n",
        "window=5\n",
        "iter=30\n",
        "sg=1\n",
        "hs=1\n"
      ],
      "metadata": {
        "id": "FK8zetWKhNt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_GEsDMOfhCP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8a186107-5d42-4da0-918a-448bedeea4ea"
      },
      "source": [
        "## 5.2.  Build vocab/dictionary for word2vec model\n",
        "start_build_vocab=time.time()\n",
        "w2v_model= Word2Vec( min_count=min_count, size=size, workers=cpu_count(), window=window, sg=sg,hs=hs) #iter=iter,\n",
        "w2v_model.build_vocab(sentences, progress_per=300000, trim_rule=None)\n",
        "print(w2v_model.corpus_total_words)\n",
        "finish_build_vocab=time.time()\n",
        "print('build_vocab time:',round(finish_build_vocab-start_build_vocab,2)/60,'mins')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18893136\n",
            "build_vocab time: 1.7215 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4nap4kW6t2v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b25b3219-9f5c-4c47-fb3e-8728c5ae318b"
      },
      "source": [
        "## 5.3 train word2vec models\n",
        "start_train=time.time()\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=w2v_model.epochs)\n",
        "finish_train=time.time()\n",
        "print('Gensim Word2Vec model training time:',round(finish_train-start_train,2)/60,'mins')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gensim Word2Vec model training time: 37.46033333333333 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6og2uxyg4AA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "d481c468-3d08-4073-f21e-7034bc679000"
      },
      "source": [
        "### 5.4 test word2vec model\n",
        "\n",
        "test_word='陳志全' #TikTok #菅義偉  #甲骨文  #沃爾瑪\n",
        "\n",
        "if test_word in w2v_model.wv.vocab:\n",
        "  query_word=test_word\n",
        "elif  test_word.lower() in w2v_model.wv.vocab:\n",
        "  query_word=test_word\n",
        "else:\n",
        "  raise (f'OOV error: {test_word} is not in w2v_model.wv.vocab')\n",
        "\n",
        "for w in w2v_model.wv.most_similar([query_word], topn=30):\n",
        "    print(w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('議會陣線', 0.7391514778137207)\n",
            "('麥嘉晉', 0.7254851460456848)\n",
            "('灑潑', 0.7130780220031738)\n",
            "('朱凱廸', 0.7068368196487427)\n",
            "('鄒家成', 0.6879165172576904)\n",
            "('李偲嫣', 0.6834797859191895)\n",
            "('廖添誠', 0.6802979707717896)\n",
            "('立法會議員', 0.676720142364502)\n",
            "('朱凱迪', 0.6760485172271729)\n",
            "('陳克勤', 0.6726042032241821)\n",
            "('郭家麒', 0.6643840074539185)\n",
            "('陳恆鑌', 0.6597760915756226)\n",
            "('公民黨', 0.6561070084571838)\n",
            "('侯志強', 0.6550020575523376)\n",
            "('人民力量', 0.6525052785873413)\n",
            "('黃潤達', 0.6483956575393677)\n",
            "('毛孟靜', 0.6458508372306824)\n",
            "('鄭松泰', 0.6438637375831604)\n",
            "('楊岳橋', 0.6401040554046631)\n",
            "('鄭達鴻', 0.6396377682685852)\n",
            "('會議廳', 0.6363130211830139)\n",
            "('葛珮帆', 0.6345359086990356)\n",
            "('扮無知', 0.6327601075172424)\n",
            "('民主派', 0.6317592859268188)\n",
            "('林卓廷', 0.6315789818763733)\n",
            "('旅館業修訂條例草案', 0.6291408538818359)\n",
            "('陳云根', 0.6289880275726318)\n",
            "('165717', 0.6288633346557617)\n",
            "('區諾軒', 0.6275712251663208)\n",
            "('朱韶洪', 0.6263978481292725)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrXdWKXMCp_E"
      },
      "source": [
        "# 新增區段"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEp2e9UyL8XG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66JbBIHu8Lia",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "d09457c8-9f62-4334-a9e6-c515a6e35b3c"
      },
      "source": [
        "### 5.5. Save word2vec model\n",
        "\n",
        "w2v_model_dir=os.path.join('/content/gdrive/My Drive/ETNET/NER/news/code/PeijiYang/predict_data','w2v_model') ##r'model', ,'w2v_model'\n",
        "news_type='etnet'\n",
        "\n",
        "w2v_model_filename='{}.model'.format('{}_w2v'.format(news_type))\n",
        "w2v_model_file=os.path.join(w2v_model_dir,w2v_model_filename)\n",
        "\n",
        "w2v_bin_filename='{}.bin'.format('{}_w2v'.format(news_type))\n",
        "w2v_bin_file=os.path.join(w2v_model_dir,w2v_bin_filename)\n",
        "\n",
        "\n",
        "w2v_model.save(w2v_model_file)  # C binary format 磁碟空間比上一方法減半\n",
        "w2v_model.wv.save_word2vec_format(w2v_bin_file, binary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht26HRevLouX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}